{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Project\n",
    "\n",
    "Your name: Ben Hoffman\n",
    "\n",
    "You abc123: Peo042\n",
    "\n",
    "Dataset: https://www.kaggle.com/dahlia25/metacritic-video-game-comments\n",
    "combined with: https://www.kaggle.com/skateddu/metacritic-critic-games-reviews-20112019\n",
    "\n",
    "## Submission Instructions\n",
    "\n",
    "After completing the exercises below, generate a pdf of the code **with** outputs. After that create a zip file containing both the completed exercise and the generated PDF/HTML. You are **required** to check the PDF/HTML to make sure all the code **and** outputs are clearly visible and easy to read. If your code goes off the page, you should reduce the line size. I generally recommend not going over 80 characters.\n",
    "\n",
    "Finally, name the zip file using a combination of your the assigment and your name, e.g., ps3_rios.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Console</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>7</td>\n",
       "      <td>7554 Glorious Memories Revived is the first bi...</td>\n",
       "      <td>GamingXP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>6</td>\n",
       "      <td>7554 deserves brownie points for trying to bre...</td>\n",
       "      <td>Absolute Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Even $12 is too much to ask for what feels lik...</td>\n",
       "      <td>PC Gamer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Nonetheless, keep your chin up, Emobi Games. T...</td>\n",
       "      <td>Eurogamer Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>7554 is a modern curiosity that plays like a s...</td>\n",
       "      <td>GameSpot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Console  Rating                                             Review  \\\n",
       "0  7554      PC       7  7554 Glorious Memories Revived is the first bi...   \n",
       "1  7554      PC       6  7554 deserves brownie points for trying to bre...   \n",
       "2  7554      PC       4  Even $12 is too much to ask for what feels lik...   \n",
       "3  7554      PC       4  Nonetheless, keep your chin up, Emobi Games. T...   \n",
       "4  7554      PC       3  7554 is a modern curiosity that plays like a s...   \n",
       "\n",
       "                User  \n",
       "0           GamingXP  \n",
       "1     Absolute Games  \n",
       "2           PC Gamer  \n",
       "3  Eurogamer Germany  \n",
       "4           GameSpot  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load in the dataset into a dataframe\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('metacritic_game_comments.csv')\n",
    "df.columns = [\"Title\",\"Console\",\"Rating\",\"Review\",\"User\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Console</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>User</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>7</td>\n",
       "      <td>7554 Glorious Memories Revived is the first bi...</td>\n",
       "      <td>GamingXP</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>6</td>\n",
       "      <td>7554 deserves brownie points for trying to bre...</td>\n",
       "      <td>Absolute Games</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Even $12 is too much to ask for what feels lik...</td>\n",
       "      <td>PC Gamer</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Nonetheless, keep your chin up, Emobi Games. T...</td>\n",
       "      <td>Eurogamer Germany</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>7554 is a modern curiosity that plays like a s...</td>\n",
       "      <td>GameSpot</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Console  Rating                                             Review  \\\n",
       "0  7554      PC       7  7554 Glorious Memories Revived is the first bi...   \n",
       "1  7554      PC       6  7554 deserves brownie points for trying to bre...   \n",
       "2  7554      PC       4  Even $12 is too much to ask for what feels lik...   \n",
       "3  7554      PC       4  Nonetheless, keep your chin up, Emobi Games. T...   \n",
       "4  7554      PC       3  7554 is a modern curiosity that plays like a s...   \n",
       "\n",
       "                User tokenized_text  sentiment  \n",
       "0           GamingXP                         0  \n",
       "1     Absolute Games                         0  \n",
       "2           PC Gamer                         0  \n",
       "3  Eurogamer Germany                         0  \n",
       "4           GameSpot                         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new columns in dataframe\n",
    "\n",
    "df['tokenized_text'] = ''\n",
    "df['sentiment'] = 0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a definitons that eliminates punctation\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def nopun(text):\n",
    "    no_pun = \"\".join(c for c in text if c not in string.punctuation)\n",
    "    return no_pun\n",
    "\n",
    "#remove stopwords and punctuation\n",
    "features = []\n",
    "\n",
    "for rev in df[\"Review\"]:\n",
    "    text = str(rev).lower()\n",
    "    token = nltk.word_tokenize(text)\n",
    "    \n",
    "    stops = set(stopwords.words('english'))\n",
    "    cleantok = [t for t in token if len(t.lower())>1 and \n",
    "                 (t.lower() not in stops)]\n",
    "    \n",
    "    clean = []\n",
    "    \n",
    "    for w in cleantok:\n",
    "        cleant = nopun(w)\n",
    "        if len(cleant.strip())>1:\n",
    "            clean.append(cleant.strip())\n",
    "    features.append(' '.join(clean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Console</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>User</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>7</td>\n",
       "      <td>7554 Glorious Memories Revived is the first bi...</td>\n",
       "      <td>GamingXP</td>\n",
       "      <td>7554 glorious memories revived first big game ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>6</td>\n",
       "      <td>7554 deserves brownie points for trying to bre...</td>\n",
       "      <td>Absolute Games</td>\n",
       "      <td>7554 deserves brownie points trying break mold...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Even $12 is too much to ask for what feels lik...</td>\n",
       "      <td>PC Gamer</td>\n",
       "      <td>even 12 much ask feels like halfhearted commun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Nonetheless, keep your chin up, Emobi Games. T...</td>\n",
       "      <td>Eurogamer Germany</td>\n",
       "      <td>nonetheless keep chin emobi games first step m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>7554 is a modern curiosity that plays like a s...</td>\n",
       "      <td>GameSpot</td>\n",
       "      <td>7554 modern curiosity plays like shabby relic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Console  Rating                                             Review  \\\n",
       "0  7554      PC       7  7554 Glorious Memories Revived is the first bi...   \n",
       "1  7554      PC       6  7554 deserves brownie points for trying to bre...   \n",
       "2  7554      PC       4  Even $12 is too much to ask for what feels lik...   \n",
       "3  7554      PC       4  Nonetheless, keep your chin up, Emobi Games. T...   \n",
       "4  7554      PC       3  7554 is a modern curiosity that plays like a s...   \n",
       "\n",
       "                User                                     tokenized_text  \\\n",
       "0           GamingXP  7554 glorious memories revived first big game ...   \n",
       "1     Absolute Games  7554 deserves brownie points trying break mold...   \n",
       "2           PC Gamer  even 12 much ask feels like halfhearted commun...   \n",
       "3  Eurogamer Germany  nonetheless keep chin emobi games first step m...   \n",
       "4           GameSpot      7554 modern curiosity plays like shabby relic   \n",
       "\n",
       "   sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add features into tokenized_text\n",
    "\n",
    "df['tokenized_text'] = [line for line in features]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load sentiment word sets\n",
    "pos = []\n",
    "neg = []\n",
    "\n",
    "posfile = list(open('positive-words.txt', encoding = 'utf-8'))\n",
    "negfile = list(open('negative-words.txt', encoding='iso-8859-1'))\n",
    "\n",
    "for p in posfile:\n",
    "    pos.append(p.strip())\n",
    "\n",
    "for n in negfile:\n",
    "    neg.append(n.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write definitions for use in sentiment analysis\n",
    "def count_pos_words(sentence):\n",
    "        num_pos_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in pos:\n",
    "                num_pos_words += 1\n",
    "        return num_pos_words\n",
    "\n",
    "def count_neg_words(sentence):\n",
    "        num_neg_words = 0\n",
    "        for word in sentence.lower().split():\n",
    "            if word in neg:\n",
    "                num_neg_words += 1\n",
    "        return num_neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine sentiment score\n",
    "score = 0\n",
    "sentiment = []\n",
    "\n",
    "for f in features:\n",
    "    score = count_pos_words(f)-count_neg_words(f)\n",
    "    sentiment.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Console</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>User</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>7</td>\n",
       "      <td>7554 Glorious Memories Revived is the first bi...</td>\n",
       "      <td>GamingXP</td>\n",
       "      <td>7554 glorious memories revived first big game ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>6</td>\n",
       "      <td>7554 deserves brownie points for trying to bre...</td>\n",
       "      <td>Absolute Games</td>\n",
       "      <td>7554 deserves brownie points trying break mold...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Even $12 is too much to ask for what feels lik...</td>\n",
       "      <td>PC Gamer</td>\n",
       "      <td>even 12 much ask feels like halfhearted commun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>Nonetheless, keep your chin up, Emobi Games. T...</td>\n",
       "      <td>Eurogamer Germany</td>\n",
       "      <td>nonetheless keep chin emobi games first step m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7554</td>\n",
       "      <td>PC</td>\n",
       "      <td>3</td>\n",
       "      <td>7554 is a modern curiosity that plays like a s...</td>\n",
       "      <td>GameSpot</td>\n",
       "      <td>7554 modern curiosity plays like shabby relic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Title Console  Rating                                             Review  \\\n",
       "0  7554      PC       7  7554 Glorious Memories Revived is the first bi...   \n",
       "1  7554      PC       6  7554 deserves brownie points for trying to bre...   \n",
       "2  7554      PC       4  Even $12 is too much to ask for what feels lik...   \n",
       "3  7554      PC       4  Nonetheless, keep your chin up, Emobi Games. T...   \n",
       "4  7554      PC       3  7554 is a modern curiosity that plays like a s...   \n",
       "\n",
       "                User                                     tokenized_text  \\\n",
       "0           GamingXP  7554 glorious memories revived first big game ...   \n",
       "1     Absolute Games  7554 deserves brownie points trying break mold...   \n",
       "2           PC Gamer  even 12 much ask feels like halfhearted commun...   \n",
       "3  Eurogamer Germany  nonetheless keep chin emobi games first step m...   \n",
       "4           GameSpot      7554 modern curiosity plays like shabby relic   \n",
       "\n",
       "   sentiment  \n",
       "0          2  \n",
       "1         -1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge sentiment into dataframe\n",
    "df['sentiment'] = [line for line in sentiment]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train (80%) test (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(df[['sentiment']],\n",
    "                                                df['Rating'], test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train model using Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and Assess predictions\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "rfcpred = rfc.predict(xtest)\n",
    "\n",
    "rfc_precision = precision_score(ytest, rfcpred, average = 'micro')\n",
    "rfc_recall = recall_score(ytest, rfcpred, average= 'micro')\n",
    "rfc_f1 = f1_score(ytest, rfcpred, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2972234421509784\n",
      "0.2972234421509784\n",
      "0.2972234421509784\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(rfc_precision)\n",
    "print(rfc_recall)\n",
    "print(rfc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train using KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "knn = KNC(n_neighbors = 5)\n",
    "\n",
    "knn.fit(xtrain, ytrain)\n",
    "\n",
    "knnpred = knn.predict(xtest)\n",
    "\n",
    "knn_precision = precision_score(ytest, knnpred, average = 'micro')\n",
    "knn_recall = recall_score(ytest, knnpred, average= 'micro')\n",
    "knn_f1 = f1_score(ytest, knnpred, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24003318206216756\n",
      "0.24003318206216756\n",
      "0.24003318206216756\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(knn_precision)\n",
    "print(knn_recall)\n",
    "print(knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up a Vectorizer on tokenized_text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TV\n",
    "\n",
    "vectorizer = TV(max_features = 2500, stop_words = stopwords.words('english'))\n",
    "\n",
    "processedvec = vectorizer.fit_transform(features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data set after the Vectorizer\n",
    "\n",
    "xtrain2, xtest2, ytrain2, ytest2 = train_test_split(processedvec,\n",
    "                                                df['Rating'], test_size = .2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rerun the RFC using the new train and test\n",
    "\n",
    "rfcvec = RandomForestClassifier()\n",
    "\n",
    "rfcvec.fit(xtrain2, ytrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and assess on the RFCvec\n",
    "\n",
    "predvec = rfcvec.predict(xtest2)\n",
    "\n",
    "vec_precision = precision_score(ytest2, predvec, average = 'micro')\n",
    "vec_recall = recall_score(ytest2, predvec, average= 'micro')\n",
    "vec_f1 = f1_score(ytest2, predvec, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4107744107744108\n",
      "0.4107744107744108\n",
      "0.4107744107744108\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(vec_precision)\n",
    "print(vec_recall)\n",
    "print(vec_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up a CountVectorizer on features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "CV = CountVectorizer(ngram_range = (1,1))\n",
    "\n",
    "cvfeat = CV.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoffm\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearSVC(), param_grid={'C': [1, 100]},\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split the CV set\n",
    "xtrain3, xtest3, ytrain3, ytest3 = train_test_split(cvfeat,\n",
    "                                                df['Rating'], test_size = .2, random_state = 0)\n",
    "\n",
    "#fit the model\n",
    "linsvc = GridSearchCV(LinearSVC(), param_grid={'C': [1, 100]}, \n",
    "                      scoring = 'f1_micro', cv = 5)\n",
    "linsvc.fit(xtrain3, ytrain3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions using the model\n",
    "svm_test_predictions = linsvc.predict(xtest3)\n",
    "\n",
    "#score the model\n",
    "svmprecision = precision_score(ytest3, svm_test_predictions, average= 'micro')\n",
    "svmrecall = recall_score(ytest3, svm_test_predictions, average= 'micro')\n",
    "svmf1 = f1_score(ytest3, svm_test_predictions, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40901771336553944\n",
      "0.40901771336553944\n",
      "0.40901771336553944\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(svmprecision)\n",
    "print(svmrecall)\n",
    "print(svmf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain4, xtest4, ytrain4, ytest4 = train_test_split(df[['tokenized_text', 'Review']],\n",
    "                                                df['Rating'], test_size = .2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up tokens for Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "vec_tok = pd.Series(df['tokenized_text']).values\n",
    "\n",
    "w2vmodel = Word2Vec(vec_tok, window = 3, min_count = 1, workers = 3, sg = 1, vector_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create word2vec vectors\n",
    "with open('trainw2v.csv', 'w+') as outfile:\n",
    "    for i, r in xtrain4.iterrows():\n",
    "        vector = (np.mean([w2vmodel.wv[t] for t in r['tokenized_text']], axis = 0)).tolist()\n",
    "        if i == 0:\n",
    "            header = ','.join(str(ele) for ele in range(1000))\n",
    "            outfile.write(header)\n",
    "            outfile.write('\\n')\n",
    "        if type(vector) is list:\n",
    "            line1 = ','.join([str(v) for v in vector])\n",
    "        else:\n",
    "            line1 = ','.join([str(0) for i in range(1000)])\n",
    "        outfile.write(line1)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up test features\n",
    "testfeat = []\n",
    "\n",
    "for i, r in xtest4.iterrows():\n",
    "    vector = (np.mean([w2vmodel.wv[t] for t in r['tokenized_text']], axis = 0)).tolist()\n",
    "    if type(vector) is list:\n",
    "          testfeat.append(vector)\n",
    "    else:\n",
    "         testfeat.append(np.array([0 for i in range(1000)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model using Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfcw2v = RandomForestClassifier()\n",
    "\n",
    "rfcmodel = pd.read_csv('trainw2v.csv')\n",
    "rfcw2v.fit(rfcmodel, ytrain4)\n",
    "w2vpred = rfcw2v.predict(testfeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score the model\n",
    "w2vprec = precision_score(ytest4, w2vpred, average= 'micro')\n",
    "w2vrec = recall_score(ytest4, w2vpred, average= 'micro')\n",
    "w2vf1 = f1_score(ytest4, w2vpred, average= 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3195969355389645\n",
      "0.3195969355389645\n",
      "0.3195969355389645\n"
     ]
    }
   ],
   "source": [
    "#Print results\n",
    "print(w2vprec)\n",
    "print(w2vrec)\n",
    "print(w2vf1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
