{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab05\n",
    "### IS6713  \n",
    "\n",
    "Instructions:\n",
    "1. Add the lines of code required to obtain the requested output. You can also insert new cells, if you need to.\n",
    "\n",
    "2. The code should be inserted where requested   \n",
    "   \n",
    "3. Do not modify other parts of this notebook.  \n",
    "  \n",
    "4. Remember to write in your name and abc123 in the first cell of this notebook.\n",
    "  \n",
    "5. Upload the notebook on Blackboard before the deadline!\n",
    "__________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name: Ben Hoffman\n",
    "#abc123: peo042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5.1\n",
    "\n",
    "Write a program that downloads and counts the total number of words in 'http://data.pr4e.org/romeo.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse as par, urllib.request as req\n",
    "import re\n",
    "\n",
    "url = \"http://data.pr4e.org/romeo.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words in Romeo.txt is 33\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "file = req.urlopen(url)\n",
    "text = []\n",
    "cnt = 0\n",
    "\n",
    "for line in file:\n",
    "    text.append(line.decode().strip()) \n",
    "    \n",
    "for i, e in enumerate(text):\n",
    "    cnt += len(text[i].split(\" \"))\n",
    "\n",
    "print('The total number of words in Romeo.txt is {}'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.2\n",
    "Write code to query http://duckduckgo.com/html/ with the key query \"data science\".  Parse the resulting page by returning all the **unique** web URLs. Return only the base URLs (http://duckduckgo.com, www.duckduckgo.com, ...)\n",
    "        \n",
    "hint: Use re.findall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse, urllib.request \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#<table class=\"wikitable sortable jquery-tablesorter\">\n",
    "\n",
    "\n",
    "\n",
    "baseurl = \"http://duckduckgo.com/html/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'www.edureka.co'}\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "Para = {'q':'data science'}\n",
    "url = baseurl + '?' + urllib.parse.urlencode(Para)\n",
    "\n",
    "html = urllib.request.urlopen(url).read().decode()\n",
    "\n",
    "sites = re.findall(r'www.[a-z]+.[a-z]+', html)\n",
    "\n",
    "print(set(sites))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5.3\n",
    "\n",
    "Find another table on Wikipedia and use the BeautifulSoup package to parse the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# you are encouraged changing the following url to try different tables\n",
    "url = 'https://en.wikipedia.org/wiki/Aircraft_carrier'\n",
    "url2 = 'https://en.wikipedia.org/wiki/Now_That%27s_What_I_Call_Music!_(original_U.S._album)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Together Again', 'Janet Jackson', '5:01']\n",
      "['As Long as You Love Me', 'Backstreet Boys', '3:32']\n",
      "['The Way', 'Fastball', '4:16']\n",
      "['Flagpole Sitta', 'Harvey Danger', '3:35']\n",
      "[\"Say You'll Be There\", 'Spice Girls', '3:56']\n",
      "['All My Life', 'K-Ci & JoJo', '5:31']\n",
      "['Never Ever (Single Edit)', 'All Saints', '4:54']\n",
      "['If You Could Only See', 'Tonic', '4:21']\n",
      "['MMMBop', 'Hanson', '4:27']\n",
      "['Zoot Suit Riot', \"Cherry Poppin' Daddies\", '3:53']\n",
      "[\"Shorty (You Keep Playin' with My Mind)\", 'Imajin', '4:54']\n",
      "['Anytime', 'Brian McKnight', '4:31']\n",
      "['Barbie Girl', 'Aqua', '3:16']\n",
      "['Karma Police', 'Radiohead', '4:21']\n",
      "['I Will Buy You a New Life', 'Everclear', '3:58']\n",
      "['Fly Away', 'Lenny Kravitz', '3:41']\n",
      "['Sex & Candy', 'Marcy Playground', '2:52']\n"
     ]
    }
   ],
   "source": [
    "#Write code here\n",
    "html = urllib.request.urlopen(url2).read()\n",
    "\n",
    "bs = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "Mytable = bs.find('table',{'class':'tracklist'})\n",
    "\n",
    "body = Mytable.find('tbody')\n",
    "\n",
    "rows = body.find_all('tr')\n",
    "\n",
    "for row in rows:\n",
    "    col = row.find_all('td')\n",
    "    col = [ele.text.strip().replace('\"', '') for ele in col]\n",
    "    print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
